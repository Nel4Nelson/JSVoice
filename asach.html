<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>JSVoice Library Single-File Test</title>
    <!-- Load Tailwind CSS for modern, responsive styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Custom styles for better visual feedback */
        #content-area {
            min-height: 800px; 
        }
        .voice-status-on {
            animation: pulse-ring 1.5s cubic-bezier(0.25, 0.46, 0.45, 0.94) infinite;
        }
        @keyframes pulse-ring {
            0% { box-shadow: 0 0 0 0px rgba(109, 40, 217, 0.5); }
            100% { box-shadow: 0 0 0 15px rgba(109, 40, 217, 0); }
        }
    </style>
</head>
<body class="bg-gray-100 text-gray-800 font-sans p-4 sm:p-6">
    
    <div class="max-w-4xl mx-auto bg-white shadow-2xl rounded-xl overflow-hidden">
        
        <!-- Header -->
        <header class="p-6 bg-indigo-700 text-white">
            <h1 class="text-3xl font-extrabold">JSVoice Interface Test</h1>
            <p class="text-indigo-200">Test the core functionality, custom commands, and real-time status updates.</p>
        </header>

        <main class="p-6">
            <!-- Status Display -->
            <div id="status-display" class="p-4 bg-indigo-100 border-l-4 border-indigo-500 text-indigo-800 rounded-lg font-medium mb-6 transition duration-300">
                Status: Awaiting Initialization...
            </div>

            <!-- Controls -->
            <div class="flex flex-col sm:flex-row items-stretch sm:items-center space-y-3 sm:space-y-0 sm:space-x-4 mb-8">
                <button id="startButton" disabled class="flex-1 px-6 py-3 bg-purple-600 hover:bg-purple-700 text-white font-bold rounded-full transition duration-150 shadow-lg disabled:opacity-50 flex items-center justify-center">
                    <svg id="mic-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" class="w-5 h-5 mr-2">
                        <path fill-rule="evenodd" d="M4.5 7.5a3 3 0 0 1 3-3h9a3 3 0 0 1 3 3v9a3 3 0 0 1-3 3h-9a3 3 0 0 1-3-3v-9Z" clip-rule="evenodd" />
                    </svg>
                    Start Voice
                </button>
                <button id="speakButton" class="flex-1 px-4 py-3 bg-gray-200 hover:bg-gray-300 text-gray-800 font-semibold rounded-full transition duration-150">
                    Test Speech Synthesis
                </button>
            </div>

            <!-- Command List -->
            <h2 class="text-xl font-bold text-gray-700 mb-3 border-b pb-2">Available Commands (Say while listening)</h2>
            <ul class="grid grid-cols-1 md:grid-cols-2 gap-3 text-sm mb-8">
                <li class="p-3 bg-indigo-50 rounded-lg shadow-sm"><span class="font-bold text-indigo-600">Custom 1:</span> "Set title to [word]"</li>
                <li class="p-3 bg-indigo-50 rounded-lg shadow-sm"><span class="font-bold text-indigo-600">Custom 2:</span> "Type [message] into the input"</li>
                <li class="p-3 bg-indigo-50 rounded-lg shadow-sm"><span class="font-bold text-indigo-600">Built-in:</span> "Click the search button"</li>
                <li class="p-3 bg-indigo-50 rounded-lg shadow-sm"><span class="font-bold text-indigo-600">Built-in:</span> "Scroll to bottom"</li>
            </ul>

            <!-- Interaction Area -->
            <div class="bg-gray-50 p-6 rounded-lg shadow-inner border border-gray-200 space-y-4">
                <h3 id="target-title" class="text-xl font-bold text-green-700">Target Title: Initial Value</h3>
                
                <label for="input-box" class="block text-sm font-medium text-gray-700">Text Input Box</label>
                <input type="text" id="input-box" placeholder="Say 'Type [message] into the input'" aria-label="Text Input Box" class="w-full p-2 border border-gray-300 rounded-lg focus:ring-indigo-500 focus:border-indigo-500">
                
                <button id="search-button" class="px-5 py-2 bg-pink-500 hover:bg-pink-600 text-white font-bold rounded-lg transition duration-150 shadow-md">
                    Search Button
                </button>
            </div>
            
            <!-- Scrollable Content -->
            <div id="content-area" class="mt-8 bg-white border border-gray-300 rounded-lg p-6 overflow-y-scroll max-h-[400px]">
                <p class="text-lg font-semibold mb-4">Content for Scroll Testing (Max Height 400px)</p>
                <div class="space-y-4">
                    <p class="p-3 bg-gray-100 rounded">Scroll Placeholder 1: The purpose of this container is to demonstrate the built-in "scroll" commands. Make sure you can see the bottom of the content by scrolling normally, then try the voice commands.</p>
                    <p class="p-3 bg-gray-100 rounded">Scroll Placeholder 2: Keep saying the full command, like "Scroll to bottom," to trigger the action. The library cleans the text and finds the best match.</p>
                    <p class="p-3 bg-gray-100 rounded">Scroll Placeholder 3: If recognition stops, the library is configured to automatically restart after a brief delay, simulating continuous listening.</p>
                    <p class="p-3 bg-gray-100 rounded">Scroll Placeholder 4: This content is artificially long to force a scrollbar on most screen sizes.</p>
                    <p class="p-3 bg-gray-100 rounded">Scroll Placeholder 5: You've scrolled about halfway!</p>
                    <p class="p-3 bg-gray-100 rounded">Scroll Placeholder 6: Almost there!</p>
                </div>
                <p class="text-center font-bold text-xl text-indigo-500 pt-4 pb-4">--- END OF SCROLLABLE CONTENT ---</p>
            </div>
        </main>
    </div>

    <script>
        // ----------------------------------------------------------------------
        // 1. HELPER FUNCTIONS (simulated utils/helpers.js)
        // ----------------------------------------------------------------------

        /** Safely calls a callback function if it exists. */
        const callCallback = (options, callbackName, ...args) => {
            if (typeof options[callbackName] === 'function') {
                options[callbackName](...args);
            }
        };

        /** Cleans text by converting to lowercase and removing punctuation/spaces. */
        const cleanText = (text) => {
            if (typeof text !== 'string') return '';
            // Note: This cleanup function is crucial for reliable command matching.
            return text.toLowerCase().replace(/[.,/#!$%^&*;:{}=?\-`~()]/g, "").trim();
        };

        // ----------------------------------------------------------------------
        // 2. COMMAND PROCESSOR (simulated modules/CommandProcessor.js)
        // ----------------------------------------------------------------------

        const processCommand = (rawTranscript, commands, updateStatus, callCallback) => {
            const cleanedTranscript = cleanText(rawTranscript);
            let actionTaken = false;

            // Process Custom Commands (Static Matches and Regex)
            for (const phrase in commands) {
                // Regex to handle commands like 'set title to (.+)'
                const phraseRegex = new RegExp('^' + phrase.replace(/(\.|\(|\)|\[|\]|\$|\^|\*|\?|\+|\{)/g, '\\$1').replace(/\s*\(\.\+\)\s*/g, '(.*?)') + '$', 'i');
                const match = rawTranscript.match(phraseRegex);

                if (match) {
                    // Execute the command callback provided by the user
                    commands[phrase](rawTranscript, cleanedTranscript);
                    updateStatus(`Command Recognized: ${rawTranscript}`);
                    callCallback('onCommandRecognized', phrase, rawTranscript);
                    return true;
                }
            }
            
            // Process Built-in Commands 
            const targetContent = document.getElementById('content-area');

            if (cleanedTranscript.includes('scroll to bottom')) {
                targetContent.scrollTop = targetContent.scrollHeight;
                updateStatus("Action: Scrolled to bottom.");
                callCallback('onActionPerformed', 'scrollToBottom', { target: '#content-area' });
                actionTaken = true;
            } else if (cleanedTranscript.includes('click the search button')) {
                const button = document.getElementById('search-button');
                if (button) {
                    button.click(); // Trigger the DOM click event
                    updateStatus("Action: Clicked the search button.");
                    callCallback('onActionPerformed', 'clickButton', { text: button.textContent.trim() });
                    actionTaken = true;
                }
            }

            if (!actionTaken) {
                updateStatus(`No command matched: ${rawTranscript}`);
                callCallback('onCommandNotRecognized', rawTranscript);
            }
            return actionTaken;
        };

        // ----------------------------------------------------------------------
        // 3. RECOGNITION MANAGER (simulated modules/RecognitionManager.js)
        // ----------------------------------------------------------------------
        
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

        const checkMicrophonePermission = (updateStatus, callCallback, state) => {
            return new Promise((resolve) => {
                // For a self-contained environment, we must trust the browser will prompt.
                state._microphoneAllowed = true; 
                if (JSVoice.isApiSupported) {
                    callCallback('onMicrophonePermissionGranted');
                    resolve();
                } else {
                    state._microphoneAllowed = false;
                    callCallback('onMicrophonePermissionDenied');
                    resolve();
                }
            });
        };

        const initRecognition = (options, updateStatus, callCallback, processCommand, startRecognitionInternal, state) => {
            if (!SpeechRecognition) return null;

            const recognition = new SpeechRecognition();
            recognition.continuous = options.continuous;
            recognition.interimResults = options.interimResults;
            recognition.lang = options.lang;

            recognition.onstart = () => {
                state._isListening = true;
                callCallback('onSpeechStart');
                updateStatus("Listening for commands...");
            };

            recognition.onend = () => {
                state._isListening = false;
                callCallback('onSpeechEnd');
                updateStatus("Recognition ended. Ready to start again.");
                if (options.autoRestart) {
                    // Auto-restart logic to simulate continuous listening
                    setTimeout(() => startRecognitionInternal(), options.restartDelay);
                }
            };

            recognition.onresult = (event) => {
                let finalTranscript = '';
                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript;
                    }
                }
                if (finalTranscript) {
                    processCommand(finalTranscript);
                }
            };

            recognition.onerror = (event) => {
                state._isListening = false;
                let errorMessage = event.error;
                if (event.error === 'not-allowed' || event.error === 'service-not-allowed') {
                    errorMessage = 'Microphone access denied by user or browser policy.';
                    state._microphoneAllowed = false; 
                }
                
                callCallback('onError', new Error(errorMessage));
                updateStatus(`Error: ${errorMessage}`);
                
                if (event.error !== 'not-allowed' && options.autoRestart) {
                   setTimeout(() => startRecognitionInternal(), options.restartDelay);
                }
            };

            return recognition;
        };
        
        // ----------------------------------------------------------------------
        // 4. JSVOICE CORE CLASS (Your main library class)
        // ----------------------------------------------------------------------
        
        class JSVoice {
            static _isApiSupported = !!(window.SpeechRecognition || window.webkitSpeechRecognition);
            
            static get isApiSupported() {
                // Ensuring consistent access to the static property
                return JSVoice._isApiSupported;
            }

            constructor(options = {}) {
                if (!JSVoice.isApiSupported) {
                    console.warn("[JSVoice] Web Speech API not supported by this browser.");
                    this._callCallback('onStatusChange', "Voice commands not supported by your browser. Try Chrome or Edge.");
                    return;
                }

                this.options = {
                    continuous: true,
                    interimResults: true,
                    lang: 'en-US',
                    commands: {},
                    autoRestart: true,
                    restartDelay: 500,
                    onSpeechStart: () => {},
                    onSpeechEnd: () => {},
                    onCommandRecognized: () => {},
                    onCommandNotRecognized: () => {},
                    onActionPerformed: () => {},
                    onMicrophonePermissionGranted: () => {},
                    onMicrophonePermissionDenied: () => {},
                    onError: () => {},
                    onStatusChange: () => {},
                    ...options,
                };
                
                this.recognition = null;
                this.speechSynthesis = window.speechSynthesis;

                this._state = {
                    _isListening: false,
                    _microphoneAllowed: false,
                };
                
                this._currentVoiceFeedback = "Initializing voice commands...";
                this._commands = {};
                
                // Pre-clean and map commands for faster processing
                for (const phrase in this.options.commands) {
                    this._commands[phrase] = this.options.commands[phrase];
                }
                
                // Initialize Recognition Manager using external function (defined above)
                this.recognition = initRecognition(
                    this.options,
                    this._updateStatus.bind(this),
                    this._callCallback.bind(this),
                    this._processCommand.bind(this),
                    this._startRecognitionInternal.bind(this),
                    this._state
                );
                
                // Initial microphone check
                this._initialMicrophoneCheckPromise = this._checkMicrophonePermission().catch(e => {
                    if (e && e.name === 'NotAllowedError') return;
                });
                
                this._updateStatus("Voice commands ready. Click mic to start.");
            }

            // Helper to call callbacks safely (using external function)
            _callCallback(callbackName, ...args) { callCallback(this.options, callbackName, ...args); }
            
            // Updates the internal status and calls the status change callback.
            _updateStatus(message) {
                this._currentVoiceFeedback = message;
                this._callCallback('onStatusChange', message);
            }
            
            // Runs the mic permission check (using external function)
            async _checkMicrophonePermission() { return checkMicrophonePermission(this._updateStatus.bind(this), this._callCallback.bind(this), this._state); }
            
            // Runs the command processing logic (using external function)
            async _processCommand(rawTranscript) { return processCommand(rawTranscript, this._commands, this._updateStatus.bind(this), this._callCallback.bind(this)); }
            
            // Internal method to safely start recognition.
            _startRecognitionInternal() {
                if (this.recognition && !this._state._isListening) {
                    try {
                        this.recognition.start();
                        return true;
                    } catch (e) {
                        if (e.name === 'InvalidStateError') {
                            this._state._isListening = true;
                            this._updateStatus("Already listening for commands.");
                            return true;
                        }
                        console.error("[JSVoice] Error attempting to start SpeechRecognition:", e);
                        this._callCallback('onError', e);
                        this._updateStatus(`Error starting voice: ${e.message}`);
                        this._state._isListening = false;
                        return false;
                    }
                } else if (this._state._isListening) {
                    this._updateStatus("Already listening for commands.");
                    return true;
                }
                return false;
            }
            
            /**
             * Starts speech recognition.
             */
            async start() {
                if (!JSVoice.isApiSupported) {
                    this._updateStatus("Voice commands not supported by your browser.");
                    return false;
                }
                
                await this._initialMicrophoneCheckPromise;

                if (!this._state._microphoneAllowed) {
                    this._updateStatus("Microphone access denied. Cannot start voice commands.");
                    return false;
                }
                
                return this._startRecognitionInternal();
            }
            
            /**
             * Stops speech recognition.
             */
            stop() {
                if (this.recognition && this._state._isListening) {
                    this.recognition.stop();
                }
            }
            
            /**
             * Toggles speech recognition on/off.
             */
            toggle() {
                if (this._state._isListening) {
                    this.stop();
                } else {
                    this.start();
                }
            }
            
            /**
             * Makes the browser speak a given text.
             */
            speak(text, lang = this.options.lang) {
                if (!this.speechSynthesis || !window.SpeechSynthesisUtterance) {
                    console.warn("[JSVoice] SpeechSynthesis not supported by this browser.");
                    this._callCallback('onError', new Error("SpeechSynthesis not supported."));
                    return;
                }
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.lang = lang;
                this.speechSynthesis.speak(utterance);
            }
            
            /**
             * Registers a custom voice command.
             */
            addCommand(phrase, callback) {
                if (typeof phrase !== 'string' || typeof callback !== 'function') {
                    console.error("[JSVoice] addCommand: Invalid phrase or callback.");
                    return;
                }
                // Store the phrase as-is for regex matching later
                this._commands[phrase] = callback; 
            }
            
            /**
             * Removes a previously registered voice command.
             */
            removeCommand(phrase) {
                if (this._commands.hasOwnProperty(phrase)) {
                    delete this._commands[phrase];
                    return true;
                }
                return false;
            }
            
            // --- Getters for status ---
            get isListening() {
                return this._state._isListening;
            }
            
            get microphoneAllowed() {
                return this._state._microphoneAllowed;
            }
            
            get isApiSupported() {
                return JSVoice.isApiSupported; 
            }
            
            get voiceFeedback() {
                return this._currentVoiceFeedback;
            }
        }

        // ----------------------------------------------------------------------
        // 5. APPLICATION INITIALIZATION (Demo Logic)
        // ----------------------------------------------------------------------
        
        document.addEventListener('DOMContentLoaded', () => {
            const statusDisplay = document.getElementById('status-display');
            const startButton = document.getElementById('startButton');
            const searchButton = document.getElementById('search-button');
            const speakButton = document.getElementById('speakButton');
            const inputBox = document.getElementById('input-box');
            const targetTitle = document.getElementById('target-title');
            
            let ui;

            // These commands must be defined exactly as you expect them to be spoken, 
            // including the (.+) capture group for variable text.
            const demoCommands = {
                'set title to (.+)': (rawTranscript) => {
                    const match = rawTranscript.match(/set title to (.+)/i);
                    if (match) {
                        const newTitle = match[1].trim();
                        targetTitle.textContent = `Target Title: ${newTitle}`;
                        ui.speak(`Title changed to ${newTitle}.`);
                    }
                },
                'type (.+) into the input': (rawTranscript) => {
                    const match = rawTranscript.match(/type (.+) into the input/i);
                    if (match) {
                        const textToType = match[1].trim();
                        inputBox.value = textToType;
                        ui.speak(`Typed ${textToType} into the input box.`);
                    }
                }
            };

            // Initialize JSVoice instance
            const uiInstance = new JSVoice({
                commands: demoCommands,
                
                onStatusChange: (message) => {
                    statusDisplay.textContent = `Status: ${message}`;
                    const isListening = ui ? ui.isListening : false;
                    startButton.textContent = isListening ? 'Stop Listening' : 'Start Voice';
                    startButton.classList.toggle('voice-status-on', isListening);
                },
                
                onError: (error) => {
                    console.error("JSVoice Error:", error);
                    statusDisplay.innerHTML = `<span class="text-red-600 font-bold">Error: ${error.message || 'Check console.'}</span>`;
                },
                
                onActionPerformed: (action, data) => {
                    // Visual feedback for built-in actions
                    if (action === 'clickButton') {
                        searchButton.classList.add('animate-pulse', 'bg-yellow-400');
                        setTimeout(() => searchButton.classList.remove('animate-pulse', 'bg-yellow-400'), 500);
                        ui.speak("Button clicked.");
                    } else if (action === 'scrollToBottom') {
                        ui.speak("Scrolled down.");
                    }
                }
            });

            ui = uiInstance;

            // Attach event listeners
            startButton.onclick = () => ui.toggle();
            speakButton.onclick = () => ui.speak("Testing the speech synthesis feature.");
            searchButton.onclick = () => {
                statusDisplay.innerHTML = `<span class="text-green-600 font-bold">Search button manually pressed.</span>`;
            };

            // Final checks on load and enabling the button
            if (ui.isApiSupported) {
                ui._initialMicrophoneCheckPromise.then(() => {
                    // Check if mic permission was granted (or assumed to be granted)
                    startButton.disabled = !ui._state._microphoneAllowed; 
                    if (!ui._state._microphoneAllowed) {
                        statusDisplay.textContent = "Status: Microphone access denied. Please allow to start voice commands.";
                    } else {
                         statusDisplay.textContent = "Status: Voice commands ready. Click Start Voice.";
                    }
                }).catch(() => {
                    startButton.disabled = true;
                    statusDisplay.textContent = "Status: Fatal error during microphone check.";
                });
            } else {
                startButton.disabled = true;
                statusDisplay.textContent = "Status: Web Speech API not supported. Please use Chrome or Edge.";
            }
        });
    </script>
</body>
</html>
